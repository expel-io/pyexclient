{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expel Metrics Examples\n",
    "This notebook provides a few examples for how you can interact with Expel data to draw some useful insights.\n",
    "\n",
    "\n",
    "\n",
    "**Requirements**\n",
    "\n",
    "Environment: `python>=3.7`\n",
    "\n",
    "Packages:\n",
    "```\n",
    "pyexclient>=0.0.1\n",
    "pandas==4.11.0\n",
    "plotly==4.11.0\n",
    "python-dateutil\n",
    "```\n",
    "\n",
    "**Using this notebook**\n",
    "- If needed, install the dependencies in the cell below\n",
    "- Run the data acquisition cell to gather data over the specified time period\n",
    "- Pick and choose following cells to see their metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you need to install dependencies!\n",
    "! pip3 install --user -i https://test.pypi.org/simple/ pyexclient>=0.0.1\n",
    "! pip3 install --user pandas==1.1.2\n",
    "! pip3 install --user plotly==4.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticating to Workbench\n",
    "Below, we're prompting you to authenticate to the Expel Workbench. This is to allow us to retrieve historical metrics that are used throught the notebook. Run the cell below, enter your credentials, and move on to the rest of the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import plotly as py\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox\n",
    "from io import BytesIO\n",
    "from dateutil import parser as dt_parser\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import display, Markdown\n",
    "from IPython.display import clear_output\n",
    "from pyexclient import WorkbenchClient\n",
    "from collections import defaultdict\n",
    "\n",
    "class WorkbenchAuth:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.uname = widgets.Text(\n",
    "            value=None,\n",
    "            placeholder='',\n",
    "            description='Username:',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.passwd =  widgets.Password(\n",
    "            value=None,\n",
    "            placeholder='',\n",
    "            description='Password:',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.mfa = widgets.Text(\n",
    "            value=None,\n",
    "            placeholder='123456',\n",
    "            description='MFA Code:',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.login = widgets.Button(\n",
    "            description='Log In',\n",
    "            disabled=False,\n",
    "            button_style='',\n",
    "            tooltip='Log In',\n",
    "            icon='check'\n",
    "        )\n",
    "        self.login.on_click(self.auth)\n",
    "        self.widgets = [self.uname, self.passwd, self.mfa, self.login]\n",
    "    \n",
    "    def auth(self, b):\n",
    "        self.wb = WorkbenchClient('https://workbench.expel.io', \n",
    "                         username=self.uname.value,\n",
    "                         password=self.passwd.value,\n",
    "                         mfa_code=self.mfa.value)\n",
    "        print(\"Success!\")\n",
    "\n",
    "    def show(self):\n",
    "        \n",
    "        display(Markdown(\"# Authenticate to Workbench\"))\n",
    "        display(VBox(self.widgets))\n",
    "        \n",
    "auth = WorkbenchAuth()\n",
    "auth.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Expel Service Metrics\n",
    "In the cell below, we're retrieving Expel service metrics over your desired time range. Run the cell, enter your start/end date, and press Confirm. Once the data has been retrieved you can check out the rest of this notebook in whatever order you'd like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get service metrics for time period\n",
    "# TODO widget this\n",
    "\n",
    "COLUMN_MAPPING = {\n",
    "    'Expel Vendor Tech Name': 'Vendor Name',\n",
    "    'Insert At (T3)': 'Created At',\n",
    "    'First Assigned To User At (T4)': 'First Assigned To User At',\n",
    "    'First Assigned User (T4 Assignee)': 'First Assigned User ID',\n",
    "    'First Assigned User Name (T4 Assignee)': 'First Assigned User Name',\n",
    "    'Time Promoted To Incident': 'Promoted To Incident At',\n",
    "    'Time First Investigative Action (T5a)': 'First Investigative Action At',\n",
    "    'Time First Remediation Action (T5b)': 'First Remediation Action At',\n",
    "    'Time First Closed (T60)': 'First Closed At',\n",
    "    'Time Last Closed (T6)': 'Last Closed At',\n",
    "    'First Assigned To Org At': 'First Notification At'\n",
    "}\n",
    "\n",
    "class MetricsWidget:\n",
    "    \n",
    "    def __init__(self, wb):\n",
    "        self.wb = wb\n",
    "        self.start = widgets.DatePicker(\n",
    "            description='Start:',\n",
    "            disabled=False,\n",
    "            value=datetime.now().date() - timedelta(days=1)\n",
    "        )\n",
    "        self.end = widgets.DatePicker(\n",
    "            description='End:',\n",
    "            disabled=False,\n",
    "            value=datetime.now().date()\n",
    "        )\n",
    "        self.button = widgets.Button(description='Confirm',\n",
    "                                                disabled=False,\n",
    "                                                button_style='',\n",
    "                                                tooltip='Confirm',\n",
    "                                                icon='check')\n",
    "        self.button.on_click(self.get_metrics)\n",
    "        self.widgets = [self.start, self.end, self.button]\n",
    "        \n",
    "    def show(self):\n",
    "        display(Markdown(\" # Choose date range to get metrics\"))\n",
    "        display(VBox(self.widgets))\n",
    "\n",
    "    def get_metrics(self, b):\n",
    "        '''\n",
    "        Retrieve Expel service metrics CSV from Workbench API\n",
    "        '''\n",
    "        start_at = datetime(self.start.value.year, self.start.value.month, self.start.value.day)\n",
    "        end_at = datetime(self.end.value.year, self.end.value.month, self.end.value.day)\n",
    "        print(f\"Requesting service metrics between {start_at.isoformat()} and {end_at.isoformat()}\")\n",
    "        url = f\"/api/v2/service_metrics/export?filter[from]={start_at.isoformat()}Z&filter[to]={end_at.isoformat()}Z\"\n",
    "        resp = self.wb.request('get', url)\n",
    "        resp.raise_for_status()\n",
    "        df = pd.read_csv(BytesIO(resp.content))\n",
    "        self.process_dataframe(df)\n",
    "\n",
    "    def minutes_to_first_action(self, row):\n",
    "        '''\n",
    "        Determine minutes to first action\n",
    "        '''\n",
    "        if row['Alert Status'] == 'NEW':\n",
    "            return -1\n",
    "        if row['First Assigned To User At']:\n",
    "            act = row['First Assigned To User At']\n",
    "        elif row['First Investigated At']:\n",
    "            act = row['First Investigated At']\n",
    "        elif row['Promoted To Incident At']:\n",
    "            act = row['Promoted To Incident At']\n",
    "        elif row['First Closed At']:\n",
    "            act = row['First Closed At']\n",
    "        act = dt_parser.parse(act)\n",
    "        ca = dt_parser.parse(row['Created At'])\n",
    "        return round((act - ca).total_seconds()/60,2)\n",
    "\n",
    "    def process_dataframe(self, df):\n",
    "        '''\n",
    "        Do some post processing on metrics to make the dataframe easier to use\n",
    "        '''\n",
    "        df = df.fillna('')\n",
    "        df = df[df.Severity!='TESTING']\n",
    "        df.rename(columns=COLUMN_MAPPING, inplace=True)\n",
    "        df['Minutes to Action'] = df.apply(self.minutes_to_first_action, axis=1)\n",
    "        df['Alert Time UTC'] = df.apply(lambda row: dt_parser.parse(row['Created At']), axis=1)\n",
    "        df = df[df['Alert Time UTC']>=pd.to_datetime(str(self.start.value)).tz_localize('UTC')]\n",
    "        self.df = df\n",
    "        print(f\"Got {len(df)} rows.\")\n",
    "\n",
    "metrics = MetricsWidget(auth.wb)\n",
    "metrics.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alerting Overview\n",
    "The cell below displays various statistics highlighting what happened over the time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = metrics.df\n",
    "md = f'''\n",
    "These are some totals that make up the Expel service delivery.\n",
    "\n",
    "* Expel generated ***{len(df)}*** expel alerts\n",
    "* Expel triaged and reviewed ***{len(df[(df['Investigation ID'] == \"\") & (df['First Notification At'] == \"\")])}*** alerts that required no action from the customer\n",
    "* Expel performed ***{len(df[(df['Investigation Type'] == 'Investigation')]['Investigation ID'].unique())}*** investigations\n",
    "* Expel identified ***{len(df[(df['Investigation Type'] == 'Incident')]['Investigation ID'].unique())}*** incidents\n",
    "* Expel notified customer of activity of interest/suspicion ***{len(df[df['First Notification At'] != \"\"])}*** times\n",
    "'''\n",
    "display(Markdown(md))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When did alerts show up?\n",
    "By looking at the day of week (and time of day) that alerts show up can help show when your team experiences the most load. This can help inform staffing decisions. At Expel, we use these metrics to decide how many analysts need to be on shift at the same time. As an Expel customer, you can see how our analysts are helping to provide visibility when you don't want to be thinking about security alerts (your off hours).\n",
    "\n",
    "**Using this cell**\n",
    "- Input your Time Zone, Work Start / End Hours, and Work Days\n",
    "- Review the PIE chart and heatmap to see when alerts typically show up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DAYS = {\n",
    "    'Monday':0,\n",
    "    'Tuesday':1,\n",
    "    'Wednesday':2,\n",
    "    'Thursday':3,\n",
    "    'Friday':4,\n",
    "    'Saturday':5,\n",
    "    'Sunday':6,\n",
    "}\n",
    "\n",
    "class WorkHoursWidget:\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.timezone = widgets.Dropdown(\n",
    "            options=pytz.all_timezones,\n",
    "            value='UTC',\n",
    "            description='Timezone:',\n",
    "            disabled=False,\n",
    "        )\n",
    "        self.work_start = widgets.Dropdown(\n",
    "            options=[i for i in range(24)],\n",
    "            value=13,\n",
    "            description='Work Starts:',\n",
    "            disabled=False,\n",
    "        )\n",
    "        self.work_end = widgets.Dropdown(\n",
    "            options=[i for i in range(24)],\n",
    "            value=21,\n",
    "            description='Work Ends:',\n",
    "            disabled=False,\n",
    "        )\n",
    "        self.work_days = widgets.SelectMultiple(\n",
    "            options=[(k,v) for k,v in DAYS.items()],\n",
    "            value=[0,1,2,3,4],\n",
    "            description='Work Days:',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.button = widgets.Button(description='Confirm',\n",
    "                                                disabled=False,\n",
    "                                                button_style='',\n",
    "                                                tooltip='Confirm',\n",
    "                                                icon='check')\n",
    "        self.button.on_click(self.show_off_hours)\n",
    "        self.widgets = [self.timezone, self.work_start, self.work_end, self.work_days, self.button]\n",
    "        \n",
    "    def show(self):\n",
    "        display(Markdown(\" # Enter your work schedule\"))\n",
    "        display(VBox(self.widgets))\n",
    "        \n",
    "    def localize(self, row):\n",
    "        '''\n",
    "        Localize timestamp based on time zone\n",
    "        '''\n",
    "        ts = dt_parser.parse(row['Created At'])\n",
    "        return ts.astimezone(pytz.timezone(self.timezone.value))\n",
    "\n",
    "    def is_off_hours(self, row):\n",
    "        '''\n",
    "        Determine if the alert was created during off hours\n",
    "        '''\n",
    "        ts = row['Alert Time Localized']\n",
    "        if ts.weekday() in self.work_days.value and ts.hour >= self.work_start.value and ts.hour < self.work_end.value:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def show_off_hours(self, b):\n",
    "        clear_output()\n",
    "        self.show()\n",
    "        self.df['Alert Time Localized'] = self.df.apply(self.localize, axis=1)\n",
    "        self.df['Is Off Hours?'] = self.df.apply(self.is_off_hours, axis=1)\n",
    "\n",
    "        # Show pie chart for on vs off hour alerts\n",
    "        pie = self.df['Is Off Hours?'].value_counts()\n",
    "        fig = go.Figure(data=[go.Pie(labels=pie.index, values=pie.values)])\n",
    "        fig.update_layout(title='Is Off Hours?')\n",
    "        fig.show()\n",
    "\n",
    "        # show heatmap of when alerts show up\n",
    "        self.df['Hour of Day'] = self.df.apply(lambda row: row['Alert Time Localized'].hour, axis=1)\n",
    "        self.df['Day of Week'] = self.df.apply(lambda row: row['Alert Time Localized'].weekday(), axis=1)\n",
    "        heatmap = self.df.groupby(['Hour of Day','Day of Week'])['Expel Alert ID'].nunique().to_frame(name='Alerts').reset_index()\n",
    "        h = defaultdict(dict)\n",
    "        z = defaultdict(list)\n",
    "\n",
    "        for _, row in heatmap.iterrows():\n",
    "            h[row['Hour of Day']][row['Day of Week']] = row['Alerts']\n",
    "\n",
    "        for hr in range(24):\n",
    "            for day in range(7):\n",
    "                z[hr].append(h[hr].get(day,0))\n",
    "\n",
    "        fig = go.Figure(data=go.Heatmap(\n",
    "                z=list(z.values()),\n",
    "                x=list(DAYS.keys()),\n",
    "                y=[i for i in range(24)],\n",
    "                colorscale='Viridis'))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title='Alert Arrival by Day of Week / Hour of Day',\n",
    "            xaxis_nticks=7, yaxis_nticks=24)\n",
    "\n",
    "        fig.show()\n",
    "        \n",
    "off_hrs = WorkHoursWidget(metrics.df)\n",
    "off_hrs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to Action\n",
    "Time to Action is the number of minutes it took before an analyst looked at an alert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdf = metrics.df[metrics.df.Severity!=\"\"].groupby(['Severity'])['Minutes to Action'].agg([np.mean, 'count']).reset_index()\n",
    "md = \"**Alert Response Time by Severity**\\n\"\n",
    "for _, row in tmpdf.iterrows():\n",
    "    md += f'* Expel saw ***{row[\"count\"]}*** {row[\"Severity\"]} alerts, '\n",
    "    md += f'on average they were looked at in ***{row[\"mean\"]:.03f}*** minutes\\n'\n",
    "\n",
    "display(Markdown(md))\n",
    "\n",
    "fig = go.Figure([go.Bar(x=tmpdf.Severity, y=tmpdf[\"mean\"])])\n",
    "fig.update_layout(title=\"Alert Response Times by Severity\",\n",
    "                  xaxis_title=\"Alert Severity\",\n",
    "                  yaxis_title=\"Avg. Minutes to Action\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Asset Values in Expel Alerts\n",
    "The below cell will gather stack the top users, hosts and Operating Systems observed in Expel Alerts for the time period. This can help you get a sense for which assets are repeat offenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Retrieve additional evidence and display top values in PIE charts\n",
    "hostnames = defaultdict(int)\n",
    "usernames = defaultdict(int)\n",
    "operatingsystems = defaultdict(int)\n",
    "d_ips = defaultdict(int)\n",
    "errors = []\n",
    "\n",
    "def flatten_json(y):\n",
    "    out = {}\n",
    "    def flatten(x, name=''):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                flatten(x[a], name + a + '.')\n",
    "        elif type(x) is list:\n",
    "            for i, a in enumerate(x):\n",
    "                flatten(a, name + str(i) + '.')\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(y)\n",
    "    return out\n",
    "\n",
    "def get_os_name(ev):\n",
    "    for key, val in flatten_json(ev).items():\n",
    "        if key.endswith('os.name'):\n",
    "            return val\n",
    "    return None\n",
    "\n",
    "print(f\"Retrieving evidence for {len(metrics.df)} alerts... this could take a few minutes\")\n",
    "i = 0\n",
    "for alert_id in metrics.df['Expel Alert ID'].unique():\n",
    "    if i > 100:\n",
    "        print(\"Stopping after 100 alerts!\")\n",
    "        break\n",
    "    try:\n",
    "        ea = auth.wb.expel_alerts.get(id=alert_id)\n",
    "    except:\n",
    "        errors.append(f\"Error retreiving evidence for expel alert {alert_id}\")\n",
    "        continue\n",
    "    found_hn = set()\n",
    "    found_un = set()\n",
    "    found_os = set()\n",
    "    found_dips = set()\n",
    "    for ev in ea.evidence:\n",
    "        if ev.evidence_type == 'HOSTNAME':\n",
    "            if ev.evidence not in found_hn:\n",
    "                hostnames[ev.evidence] += 1\n",
    "                found_hn.add(ev.evidence)\n",
    "        elif ev.evidence_type == 'USERNAME':\n",
    "            if ev.evidence not in found_un:\n",
    "                usernames[ev.evidence] += 1\n",
    "                found_un.add(ev.evidence)\n",
    "        elif ev.evidence_type == 'DST_IP':\n",
    "            if ev.evidence not in found_dips:\n",
    "                d_ips[ev.evidence] += 1\n",
    "                found_dips.add(ev.evidence)\n",
    "    for va in ea.vendor_alerts:\n",
    "        os = get_os_name(va.evidence_summary)\n",
    "        if os not in found_os:\n",
    "            operatingsystems[os] += 1\n",
    "            found_hn.add(os)\n",
    "    i += 1\n",
    "print(f\"Retrieved evidence with {len(errors)} errors\")\n",
    "\n",
    "if hostnames:\n",
    "    fig1 = go.Figure(data=[go.Pie(labels=list(hostnames.keys()), values=list(hostnames.values()))])\n",
    "    fig1.update_layout(title='Top Host Names')\n",
    "    fig1.show()\n",
    "else:\n",
    "    print(\"No hostnames found in Expel Alerts\")\n",
    "\n",
    "if usernames:\n",
    "    fig2 = go.Figure(data=[go.Pie(labels=list(usernames.keys()), values=list(usernames.values()))])\n",
    "    fig2.update_layout(title='Top User Names')\n",
    "    fig2.show()\n",
    "else:\n",
    "    print(\"No usernames found in Expel Alerts\")\n",
    "\n",
    "if operatingsystems:\n",
    "    fig3 = go.Figure(data=[go.Pie(labels=list(operatingsystems.keys()), values=list(operatingsystems.values()))])\n",
    "    fig3.update_layout(title='Top Operating Systems')\n",
    "    fig3.show()\n",
    "else:\n",
    "    print(\"No operating systems found in Expel Alerts\")\n",
    "    \n",
    "if d_ips:\n",
    "    fig4 = go.Figure(data=[go.Pie(labels=list(d_ips.keys()), values=list(d_ips.values()))])\n",
    "    fig4.update_layout(title='Top Destination IPs')\n",
    "    fig4.show()\n",
    "else:\n",
    "    print(\"No destination IPs found in Expel Alerts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change point analysis\n",
    "Change point analysis allows you to spot statistically significant, sustained changes in timeseries data. Statistically significant just means that it's a change that is beyond the typical daily fluctuation and big enough that we should care about it.  For example, say we normally see around 100 Expel Alerts a day but suddenly we start seeing 300 a day. The first day we saw 300 would be considered a \"change point\" indicating that something has caused our metrics to behave differently. This kind of analysis can be really useful to pinpoint when things change and spur further investigation into the root cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "def cumsums(data):\n",
    "    \"\"\"\n",
    "    Description:    Calculates the cumulative sums \n",
    "    Arguments:      data - a list of floats\n",
    "    \"\"\"\n",
    "    \n",
    "    series_average = np.average(data)\n",
    "    csums = []\n",
    "    csums.append(0)\n",
    "    \n",
    "    for i in range(0, len(data)):\n",
    "        csums.append( (data[i] - series_average) + csums[i])\n",
    "    return csums    \n",
    "\n",
    "def randomize(data):\n",
    "    temp_list = []\n",
    "    temp_list.extend(data)\n",
    "    \n",
    "    result = []\n",
    "    for i in range(len(temp_list)):\n",
    "        element = random.choice(temp_list)\n",
    "        temp_list.remove(element)\n",
    "        result.append(element)\n",
    "    return result\n",
    "    \n",
    "def bootstrap(data, iterations=1000):\n",
    "    \"\"\"\n",
    "    Description:    used, along with the confidence interval,\n",
    "                    to detect if a change occurred int he series.\n",
    "                    Creates 100 bootsrapped series, shuffles the original data list\n",
    "                    then calculates the cumulative sum for each shuffled data series\n",
    "    Arguments:      data - a list of floats\n",
    "    Returns:        returns the confidence interval\n",
    "    \"\"\"\n",
    "    \n",
    "    cumsum_original = cumsums(data)\n",
    "    sdiff_original = max(cumsum_original) - min(cumsum_original)\n",
    "    \n",
    "    #boot strap n samples\n",
    "    bootstrapped_series = [randomize(data) for i in range(iterations)]\n",
    "    \n",
    "    #find cumumlative sums for the bootstrapped samples\n",
    "    bootstrapped_cumsums = [cumsums(bootstrapped_series[i]) for i in range(len(bootstrapped_series))]\n",
    "    x = [max(bootstrapped_cumsums[i]) - min(bootstrapped_cumsums[i]) for i in range(len(bootstrapped_series))]\n",
    "    \n",
    "    #find the number of bootstrapped series where\n",
    "    #S_diff is < S_diff of the original series\n",
    "    n = 0\n",
    "    for i in range(len(x)):\n",
    "        if (x[i] < sdiff_original):\n",
    "            n = n + 1    \n",
    "\n",
    "    s =  (n/float(iterations)) * 100.0\n",
    "    return s\n",
    "    \n",
    "def find_index_of_maximum(cumsum):\n",
    "    \"\"\"\n",
    "    Description:  Find the index of the maximum value from the cummulative sums\n",
    "    \"\"\"\n",
    "    max_number = sys.float_info.min\n",
    "    max_index = 0\n",
    "    abs_vals = [abs(x) for x in cumsum]\n",
    "\n",
    "    for (i, num) in enumerate(abs_vals):\n",
    "        if num > max_number:\n",
    "            max_number = num\n",
    "            max_index = i\n",
    "        \n",
    "    return max_index\n",
    "\n",
    "def get_changepoints(data, change_points, confidence_level = 95, offset = 0):\n",
    "    \"\"\"\n",
    "    Description:    Call the function by passing a data series \n",
    "                    Once a change has been detected, break the data into two segments,\n",
    "                    one each side of the change-point, and the analysis repeated for each segment.                   \n",
    "    Returns:        Indexes of change points detected in the data series\n",
    "    \"\"\"\n",
    "    if not change_points:\n",
    "        change_points = []\n",
    "\n",
    "    confidence = bootstrap(data, 1000)\n",
    "    if (confidence > confidence_level):\n",
    "        cumsum = cumsums(data)\n",
    "        max_index = find_index_of_maximum(cumsum)\n",
    "\n",
    "        #add change point found to list\n",
    "        #use offset to find the correct index based on original data\n",
    "        change_points.extend([max_index + offset])\n",
    "\n",
    "        #split the data into two, and calculate change points\n",
    "        get_changepoints(data[:max_index], change_points, confidence_level, offset)\n",
    "        get_changepoints(data[max_index:], change_points, confidence_level, offset + max_index - 1)\n",
    "\n",
    "    return change_points\n",
    "\n",
    "def ff_ts_with_changepoints(x_vals, y_vals, change_points, title):\n",
    "    \"\"\"\n",
    "    Create a figure of a timeseries with changepoints marked.\n",
    "    \"\"\"\n",
    "    layout = {\n",
    "            'title' : title,\n",
    "            'showlegend' : False,\n",
    "            'shapes' : [ ] \n",
    "    }\n",
    "\n",
    "    last = 0\n",
    "    cpoint_height = max(y_vals)\n",
    "    for i in change_points:\n",
    "        cpoint = x_vals[i]\n",
    "        # Add a vertical line for the changepoint location.\n",
    "        layout['shapes'].append(\n",
    "                    {\n",
    "                        'type': 'line',\n",
    "                        'x0': cpoint,\n",
    "                        'y0': 0,\n",
    "                        'x1': cpoint,\n",
    "                        'y1': cpoint_height,\n",
    "                        'line': {\n",
    "                            'color': 'rgb(255,0,0)',\n",
    "                            'width': 4,\n",
    "                            'dash': 'dot',\n",
    "                        },\n",
    "                    })\n",
    "        # Add a horizontal line for the mean in this regime.\n",
    "        new_mean = np.mean(y_vals[last:i])\n",
    "        print(\"Mean: {}\".format(new_mean))\n",
    "        layout['shapes'].append(\n",
    "                    {\n",
    "                        'type': 'line',\n",
    "                        'x0': x_vals[last],\n",
    "                        'y0': new_mean,\n",
    "                        'x1': cpoint,\n",
    "                        'y1': new_mean,\n",
    "                        'line': {\n",
    "                            'color': 'rgb(211,211,0)',\n",
    "                            'width': 4,\n",
    "                            'dash': 'dot',\n",
    "                        },\n",
    "                    })\n",
    "        last = i\n",
    "\n",
    "    new_mean = np.mean(y_vals[last:-1])\n",
    "    print(\"Mean: {}\".format(new_mean))\n",
    "    layout['shapes'].append(\n",
    "                {\n",
    "                    'type': 'line',\n",
    "                    'x0': x_vals[last],\n",
    "                    'y0': new_mean,\n",
    "                    'x1': x_vals[-1],\n",
    "                    'y1': new_mean,\n",
    "                    'line': {\n",
    "                        'color': 'rgb(211,211,0)',\n",
    "                        'width': 4,\n",
    "                        'dash': 'dot',\n",
    "                    },\n",
    "                })\n",
    "    layout['shapes'].append(\n",
    "                {\n",
    "                    'type': 'line',\n",
    "                    'x0': x_vals[0],\n",
    "                    'x1': x_vals[-1],\n",
    "                    'line': {\n",
    "                        'color': 'gray',\n",
    "                        'width': 4,\n",
    "                        'dash': 'dashdot',\n",
    "                    },\n",
    "\n",
    "                })\n",
    " \n",
    "    \n",
    "    trace = go.Scatter(\n",
    "            x = x_vals,\n",
    "            y = y_vals,\n",
    "            name = \"Events\"\n",
    "       )\n",
    "    \n",
    "    data = [trace]\n",
    "    \n",
    "    fig = dict(data=data, layout=layout)\n",
    "  \n",
    "    return fig\n",
    "\n",
    "change_points = []\n",
    "temp = metrics.df.copy()\n",
    "temp['Date'] = temp.apply(lambda row: dt_parser.parse(row['Created At']).date(), axis=1)\n",
    "temp = temp.groupby(['Date'])['Expel Alert ID'].nunique().to_frame(name='alert_count').reset_index()\n",
    "temp = temp.set_index('Date')\n",
    "idx = pd.date_range(temp.index[0], temp.index[-1])\n",
    "temp = temp.reindex(idx, fill_value=0)\n",
    "points = get_changepoints(list(temp.alert_count), change_points)\n",
    "points.sort()\n",
    "print(\"Change Points: \", points)\n",
    "\n",
    "#Graph changepoints\n",
    "#plt.figure(figsize = (10,5))\n",
    "fig = ff_ts_with_changepoints(temp.index, temp.alert_count, points, 'Expel Alert Timeseries w/ Change Points')\n",
    "f = go.Figure(fig)\n",
    "f.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-test",
   "language": "python",
   "name": "python3-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
